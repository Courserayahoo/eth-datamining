\documentclass[a4paper, 11pt]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage[pdftex]{hyperref}

\setlength{\textwidth}{16.5cm}
\setlength{\marginparwidth}{1.5cm}
\setlength{\parindent}{0cm}
\setlength{\parskip}{0.15cm}
\setlength{\textheight}{22cm}
\setlength{\oddsidemargin}{0cm}
\setlength{\evensidemargin}{\oddsidemargin}
\setlength{\topmargin}{0cm}
\setlength{\headheight}{0cm}
\setlength{\headsep}{0cm}

\renewcommand{\familydefault}{\sfdefault}

\title{Data Mining: Learning from Large Data Sets - Spring Semester 2014}
\author{jerik@student.ethz.ch\\ member2@student.ethz.ch\\ member3@student.ethz.ch\\}
\date{\today}

\begin{document}
\maketitle

\section{Approximate near-duplicate search using Locality Sensitive Hashing} 
To solve this problem we used a min-hashing on the mapper with partitioning with a lower target threshhold and then manually running jaccard to find hash out the false positives.

	\subsection{Min-Hashing on the Mapper}
		We start by generating the permutations which we're going to use. We use a hashing function in the form
			\[h(x) = a_0x + a_1 \mod N\]
		where N is the number of features (i.e. $10000$), and $a_0$ and $a_1$ is uniformly randomly generated. We generate 256 permutations. Incidently, we use, for the signature matrix, 16 rows and 16 bands.

		After this we generate the signature matrix. We do this by reading the next video descriptor, i.e. all the shingles, and then performing this algorithm:
		\begin{verbatim}
			  set M to be row vector of length 256 with each element infinity
			  for i=1:10000 do
			    if current video has shingle s, do
			      for each hash function h_i, do
			        if h_i(s) < M(i), do
			          set M(i) = h_i(s)
			  return M
		\end{verbatim}
		So now $M$ represents the column in the signature matrix which represents the current video. 

		Now we iterate; for each band $B$:
		\begin{verbatim}
			  set M according to the algorithm above
			  set key = ''
			  for each row R in band B, do
			    append M(R) to key
			    emit(key, value)
		\end{verbatim}

		where $value$ is the video ID.\\
		Now read the next video and repeat.
 		
	\subsection{Detecting duplicates on the reducer}
		Now, since we emit the signature as the key, and the MapReduce environment sorts out data based on the keys, we can get all videos with the same key serially. And since we used 16 bands with 16 rows, we have a threshold of 0.8 = 80\% (target is 85\%). Hence we will get some false positives, but few false negatives.\\

		So we collect all videos with the same key (signature) and we run a jaccard similarity measurement between all the videos with this key, and if they have at least 85\% similarity we emit this as a duplicate.

	\subsection{Result}
		This resulted in a score of 0.99, close to the perfect 1.0. It would be trivial to reach 1.0  (by tweaking the number of band and rows to get a lower threshhold before manually running jaccard similarity), but since we would not gain anything by this we did not do it. 

\section{Large-Scale Image Classification}
Maximum of 2 pages per section.

\section{Extracting Representative Elements From Large Datasets}
Maximum of 2 pages per section.

\section{Explore-Exploit Tradeoffs in Recommender Systems}
Maximum of 2 pages per section.

\end{document} 
